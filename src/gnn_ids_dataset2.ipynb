{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from ag_utils import Corpus\n",
    "from ag_utils import parse_ag_file\n",
    "from ag_utils import parse_node_properties\n",
    "\n",
    "from public_data import gene_dataset\n",
    "\n",
    "from models import NN, GCN, GCN_EW, GAT\n",
    "from model_utils import train, predict_prob, evaluate_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse attack graph file generated by MulVAL tool\n",
    "attack_graph_path = '../mulval_attack_graph/AttackGraph.dot'\n",
    "nodes, edges, node_properties = parse_ag_file(attack_graph_path)\n",
    "node_dict = parse_node_properties(nodes, node_properties)\n",
    "\n",
    "# save node label into corpus object\n",
    "corpus = Corpus(node_dict)\n",
    "num_tokens = corpus.get_num_tokens()\n",
    "node_features = corpus.get_node_features()\n",
    "node_types = corpus.get_node_types()\n",
    "vocab_size = len(corpus.dictionary)\n",
    "print('vocab_size: ', vocab_size)\n",
    "print('num_tokens: ', num_tokens)\n",
    "print('node_features shape: ', node_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics of the encoded attack graph\n",
    "num_nodes = len(nodes)\n",
    "print('num_nodes: ', num_nodes)\n",
    "\n",
    "num_node_features = node_features.shape[1]\n",
    "print('num_node_features: ', num_node_features)\n",
    "\n",
    "num_edges = len(edges)\n",
    "print('num_edges: ', num_edges)\n",
    "\n",
    "action_nodes = corpus.get_action_nodes()\n",
    "action_node_idx = list(action_nodes.keys())\n",
    "num_action_nodes = len(action_node_idx)\n",
    "print('action_node_idx: ', action_node_idx)\n",
    "print('num_action_nodes: ', num_action_nodes)\n",
    "\n",
    "# var 'action_mask' is used to represent the attack scenarios in attack graph (i.e., the privilege nodes)\n",
    "action_mask = action_node_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj matrix and edge index\n",
    "adj_matrix = torch.zeros(len(nodes), len(nodes))\n",
    "\n",
    "for edge in edges:\n",
    "    source_node, target_node = edge\n",
    "    source_index = nodes.index(source_node)\n",
    "    target_index = nodes.index(target_node)\n",
    "    adj_matrix[source_index][target_index] = 1\n",
    "\n",
    "edge_index = adj_matrix.nonzero().t().contiguous()\n",
    "\n",
    "assert edge_index.shape[0]==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare Dataset 2\n",
    "num_benign = 1500\n",
    "num_malic = 500\n",
    "sample_method = 'public'\n",
    "\n",
    "X, Y= gene_dataset(action_node_idx, num_nodes, num_benign, num_malic)\n",
    "rt_meas_dim = X.shape[2]\n",
    "\n",
    "# associate node features in attack graph with real-time measurements\n",
    "node_feat_ts = torch.stack([node_features for _ in range(len(X))], dim=0)\n",
    "X = torch.cat((node_feat_ts, X), dim=2)\n",
    "\n",
    "num_samples = X.shape[0]\n",
    "print('num_samples: ', num_samples)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=42, stratify=Y_train)\n",
    "print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Dataset 2 used in the paper\n",
    "data_path = '../datasets/public/'\n",
    "X_train = torch.load(data_path+'X_train-{}.pth'.format(sample_method))\n",
    "X_val   = torch.load(data_path+'X_val-{}.pth'.format(sample_method))\n",
    "X_test  = torch.load(data_path+'X_test-{}.pth'.format(sample_method))\n",
    "Y_train = torch.load(data_path+'Y_train-{}.pth'.format(sample_method))\n",
    "Y_val   = torch.load(data_path+'Y_val-{}.pth'.format(sample_method))\n",
    "Y_test  = torch.load(data_path+'Y_test-{}.pth'.format(sample_method))\n",
    "print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hyperparameters for training\n",
    "in_dim = X_train.shape[-1]\n",
    "hidden_dim = 20\n",
    "out_dim = 1\n",
    "lr = 0.001\n",
    "device = 'cpu'\n",
    "# model initialization\n",
    "models = {}\n",
    "model_NN = NN(78, hidden_dim, out_dim)\n",
    "model_GCN = GCN(in_dim, hidden_dim, out_dim)\n",
    "model_GCN_EW = GCN_EW(in_dim, hidden_dim, out_dim, edge_index)\n",
    "model_GAT = GAT(hidden_channels=hidden_dim, heads=4, in_dim=in_dim, out_dim=out_dim)\n",
    "\n",
    "models['NN'] = model_NN\n",
    "models['GCN'] = model_GCN\n",
    "models['GCN-EW'] = model_GCN_EW\n",
    "models['GAT'] = model_GAT\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.name = name\n",
    "    model.action_mask = action_mask\n",
    "\n",
    "    num_epochs = 2 # early stop when overfitting observed\n",
    "    print(f'{model.name} start training...')\n",
    "    time_start = time.time()\n",
    "    print('model: ', model) \n",
    "    train(model, lr, num_epochs, X_train, Y_train, X_val, Y_val, edge_index, rt_meas_dim, device)       \n",
    "    time_end = time.time()\n",
    "    print('time cost: ', time_end - time_start)  \n",
    "    print(f'{model.name} training finished!')\n",
    "\n",
    "    print(f'{model.name} accuracy on training set: {model.stat[\"acc_train\"][-1]}')\n",
    "    print(f'{model.name} accuracy on validation set: {model.stat[\"acc_val\"][-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the roc curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "for name, model in models.items():\n",
    "    prob = predict_prob(model, X_test, edge_index)\n",
    "    y_probs = prob.view(-1, 2)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test.view(-1), y_probs[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    ax.plot(fpr, tpr, label='{} (AUC = {:.4f})'.format(model.name, roc_auc))\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "ax.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_performance(models, X_test, Y_test, edge_index, device)\n",
    "df = pd.DataFrame(metrics)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the TP, FP, TN, FN for each model\n",
    "fig, axs = plt.subplots(2, 2, figsize=(5, 5))\n",
    "axs = axs.ravel()\n",
    "\n",
    "bar_width = 0.5\n",
    "labels = ['TN', 'FP', 'FN', 'TP']\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    for j, name in enumerate(models):\n",
    "        rects = axs[i].bar(j, metrics[j][label], width=bar_width, label=name)\n",
    "    axs[i].set_xticks(np.arange(len(models)))\n",
    "    axs[i].set_xticklabels(models.keys())\n",
    "    for tick in axs[i].xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(10)\n",
    "    axs[i].set_title(label)\n",
    "\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(1.2, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robustness evaluation\n",
    "for i in range(Y_test.shape[0]):\n",
    "    for j in range(len(action_mask)):\n",
    "        if Y_test[i, j] == 1:\n",
    "            for k in range(rt_meas_dim):\n",
    "                X_test[i, action_mask[j],-rt_meas_dim+k] += torch.normal(mean=0, std=0.01, size=(1,)).item()\n",
    "\n",
    "metrics = evaluate_performance(models, X_test, Y_test, edge_index, device)\n",
    "df = pd.DataFrame(metrics)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.explain import GNNExplainer, Explainer\n",
    "\n",
    "# individual case analysis\n",
    "found = False\n",
    "while not found:\n",
    "    indi_case_id = torch.randint(0, X_test.shape[0], (1,)).item()\n",
    "    y_true = Y_test[indi_case_id]\n",
    "    if y_true[2] != 0:\n",
    "        found = True\n",
    "        print('indi_case_id: ', indi_case_id)\n",
    "indi_case_x = X_test[indi_case_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainability visualization\n",
    "\n",
    "model_to_explain = model_GCN_EW\n",
    "model_to_explain.eval()\n",
    "if model.name in ['GAT']:\n",
    "    indi_case_x = indi_case_x.view(-1, in_dim)\n",
    "prob_ts = torch.sigmoid(model_to_explain(indi_case_x, edge_index))[action_mask]\n",
    "\n",
    "print('model prob_ts: \\n', prob_ts)\n",
    "print('y_true: ', y_true)\n",
    "\n",
    "data = Data(x=X_test[indi_case_id], edge_index=edge_index)\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model_to_explain,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='raw',\n",
    "    ),\n",
    "\n",
    ")\n",
    "\n",
    "feat_labels_ag = corpus.dictionary.idx2word.values()\n",
    "feat_labels_ag = list(feat_labels_ag)\n",
    "feat_labels_rtm = pd.read_csv('../datasets/public/CICIDS-2017.csv').columns.tolist()[:-1]\n",
    "feat_labels_rtm = [feat.strip() for feat in feat_labels_rtm]\n",
    "feat_labels = feat_labels_ag + feat_labels_rtm\n",
    "\n",
    "compromised_node = action_node_idx[np.where(y_true==1)[0].item()]\n",
    "explanation = explainer(data.x, data.edge_index, index=compromised_node)\n",
    "\n",
    "explanation.visualize_feature_importance(feat_labels=feat_labels, top_k=10)\n",
    "explanation.visualize_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
